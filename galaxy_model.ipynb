{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--batch-size N] [--test-batch-size N]\n",
      "                             [--epochs N] [--lr LR] [--momentum M] [--no-cuda]\n",
      "                             [--seed S] [--log-interval N]\n",
      "                             [--save-path SAVE_PATH] [--load-path LOAD_PATH]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\tx\\AppData\\Roaming\\jupyter\\runtime\\kernel-d383051b-cac2-4462-a8fa-b2e632d80dac.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFiles\\Anaconda2\\envs\\py35\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn import manifold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "\n",
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                    help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=True,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--save-path', default='checkpoint/', type=str)\n",
    "parser.add_argument('--load-path', default='checkpoint/_15.pth.tar', type=str)\n",
    "args = parser.parse_args()\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)  # 为CPU设置种子用于生成随机数，以使得结果是确定的\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)  # 为当前GPU设置随机种子；如果使用多个GPU，应该使用torch.cuda.manual_seed_all()为所有的GPU设置种子。\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "\"\"\"加载数据。组合数据集和采样器，提供数据上的单或多进程迭代器\n",
    "参数：\n",
    "dataset：Dataset类型，从其中加载数据\n",
    "batch_size：int，可选。每个batch加载多少样本\n",
    "shuffle：bool，可选。为True时表示每个epoch都对数据进行洗牌\n",
    "sampler：Sampler，可选。从数据集中采样样本的方法。\n",
    "num_workers：int，可选。加载数据时使用多少子进程。默认值为0，表示在主进程中加载数据。\n",
    "collate_fn：callable，可选。\n",
    "pin_memory：bool，可选\n",
    "drop_last：bool，可选。True表示如果最后剩下不完全的batch,丢弃。False表示不丢弃。\n",
    "\"\"\"\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])),\n",
    "    batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.Linear(784, 1000, bias=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(inplace=True),)\n",
    "        self.stage2 = nn.Sequential(\n",
    "            nn.Linear(1000, 1000, bias=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.ReLU(inplace=True),)\n",
    "        self.stage3 = nn.Sequential(\n",
    "            nn.Linear(1000, 1000, bias=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.ReLU(inplace=True),)\n",
    "        self.stage4 = nn.Sequential(\n",
    "            nn.Linear(1000, 1000, bias=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(inplace=True),)\n",
    "        self.stage5 = nn.Sequential(\n",
    "            nn.Linear(1000, num_classes, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "        )\n",
    "        self.classifier = nn.Softmax(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stage1(x)\n",
    "        layer1_out = x\n",
    "        x = self.stage2(x)\n",
    "        layer2_out = x\n",
    "        x = self.stage3(x)\n",
    "        layer3_out = x\n",
    "        x = self.stage4(x)\n",
    "        layer4_out = x\n",
    "        x = self.stage5(x)\n",
    "        x = x.view(-1, self.num_classes)\n",
    "        x = self.classifier(x)\n",
    "        return x, layer1_out, layer2_out, layer3_out, layer4_out\n",
    "\n",
    "\n",
    "model = Net()\n",
    "if args.cuda:\n",
    "    model.cuda()  # 将所有的模型参数移动到GPU上\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()  # 把module设成training模式，对Dropout和BatchNorm有影响\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(\n",
    "            target)  # Variable类对Tensor对象进行封装，会保存该张量对应的梯度，以及对生成该张量的函数grad_fn的一个引用。如果该张量是用户创建的，grad_fn是None，称这样的Variable为叶子Variable。\n",
    "        data = data.view(-1, 784)\n",
    "        # print(target.size())\n",
    "        optimizer.zero_grad()\n",
    "        output, layer1_out, layer2_out, layer3_out, layer4_out = model(data)\n",
    "        loss = F.nll_loss(output, target)  # 负log似然损失\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()  # 把module设置为评估模式，只对Dropout和BatchNorm模块有影响\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        data = data.view(-1, 784)\n",
    "        output, layer1_out, layer2_out, layer3_out, layer4_out = model(data)\n",
    "        test_loss += F.nll_loss(output, target).data[0]  # Variable.data\n",
    "        pred = output.data.max(1)[1]  # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    test_loss = test_loss\n",
    "    test_loss /= len(test_loader)  # loss function already averages over batch size\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "def test_with_tsne(model_path):\n",
    "    load_state(model_path, model)\n",
    "    model.eval()  # 把module设置为评估模式，只对Dropout和BatchNorm模块有影响\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    data_all = Variable()\n",
    "    first = True\n",
    "    print('start test:')\n",
    "    for data, target in test_loader:\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        if first :\n",
    "            data_all, target_all = Variable(data, volatile=True), Variable(target)\n",
    "            data_all = data_all.view(-1, 784)\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        data = data.view(-1, 784)\n",
    "        data_all = torch.cat((data, data_all), 0)\n",
    "        # print(data_all.size())\n",
    "\n",
    "        output, layer1_out, layer2_out, layer3_out, layer4_out = model(data)\n",
    "        test_loss += F.nll_loss(output, target).data[0]  # Variable.data\n",
    "        if first:\n",
    "            pred_all = output.data.max(1)[1]\n",
    "            layer1_out_all = layer1_out\n",
    "            layer2_out_all = layer2_out\n",
    "            layer3_out_all = layer3_out\n",
    "            layer4_out_all = layer4_out\n",
    "            first = False\n",
    "\n",
    "        pred = output.data.max(1)[1]  # get the index of the max log-probability\n",
    "        pred_all = torch.cat((pred, pred_all), 0)\n",
    "        layer1_out_all = torch.cat((layer1_out, layer1_out_all), 0)\n",
    "        layer2_out_all = torch.cat((layer2_out, layer2_out_all), 0)\n",
    "        layer3_out_all = torch.cat((layer3_out, layer3_out_all), 0)\n",
    "        layer4_out_all = torch.cat((layer4_out, layer4_out_all), 0)\n",
    "        # print(pred_all.size())\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "    # print(data_all.size())\n",
    "    # print(pred_all.size())\n",
    "    test_loss = test_loss\n",
    "    test_loss /= len(test_loader)  # loss function already averages over batch size\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "    print(\"Computing t-SNE embedding\")\n",
    "    # tsne = manifold.TSNE(n_components=2, init='random', random_state=0)\n",
    "    layer1_out_all = layer1_out_all.data.numpy()\n",
    "    layer2_out_all = layer2_out_all.data.numpy()\n",
    "    layer3_out_all = layer3_out_all.data.numpy()\n",
    "    layer4_out_all = layer4_out_all.data.numpy()\n",
    "    # data_all = pd.DataFrame(data_all, index=data_all[:, 0]),\n",
    "    tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "    layer1_out_all_tsne = np.array(tsne.fit_transform(layer1_out_all))[:, np.newaxis, :]\n",
    "    layer2_out_all_tsne = np.array(tsne.fit_transform(layer2_out_all))[:, np.newaxis, :]\n",
    "    layer3_out_all_tsne = np.array(tsne.fit_transform(layer3_out_all))[:, np.newaxis, :]\n",
    "    layer4_out_all_tsne = np.array(tsne.fit_transform(layer4_out_all))[:, np.newaxis, :]\n",
    "\n",
    "    layerout_tsne = layer1_out_all_tsne\n",
    "    layerout_tsne = np.concatenate((layerout_tsne, layer2_out_all_tsne), axis=1)\n",
    "    layerout_tsne = np.concatenate((layerout_tsne, layer3_out_all_tsne), axis=1)\n",
    "    layerout_tsne = np.concatenate((layerout_tsne, layer4_out_all_tsne), axis=1)\n",
    "    np.save('layerout_tsne.npy', layerout_tsne)\n",
    "    # layerout_tsne = np.load('layerout_tsne.npy')\n",
    "    # print(layerout_tsne.shape)\n",
    "    # tsne = pd.DataFrame(tsne.embedding_, index=data_all.index)  # 转换数据格式\n",
    "\n",
    "    colors = ['red', 'm', 'cyan', 'blue', 'lime', 'lawngreen', 'lightcoral', 'lightyellow', 'mediumorchid', 'mediumpurple']\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    print('start plot:')\n",
    "    for i in range(len(colors)):\n",
    "        px = []\n",
    "        py = []\n",
    "        px2 = []\n",
    "        py2 = []\n",
    "        for j in range(1000):\n",
    "            if pred_all[j] == i :\n",
    "                plt.plot(layerout_tsne[j,:,0], layerout_tsne[j,:,1])\n",
    "                # px.append(layerout_tsne[j, 0])\n",
    "                # py.append(layerout_tsne[j, 1])\n",
    "\n",
    "        # plt.scatter(px, py, s=20, c=colors[i], marker='o')\n",
    "        # plt.scatter(px2, py2, s=20, c=colors[i], marker='v')\n",
    "\n",
    "    # plt.legend(np.arange(0,5).astype(str))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    # plt.savefig('C:/Users/Day/Desktop/PPT_report/Galaxy pic/Visualization/2/cnn1_train.png', dpi=300, bbox_inches='tight')\n",
    "    plt.savefig('1.png', dpi=300,\n",
    "                bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def pretrain(model, state_dict):\n",
    "    own_state = model.state_dict()\n",
    "    for name, param in state_dict.items():\n",
    "        if name in own_state:\n",
    "            if isinstance(param, torch.nn.Parameter):\n",
    "                # backwards compatibility for serialized parameters\n",
    "                param = param.data\n",
    "            try:\n",
    "                own_state[name].copy_(param)\n",
    "            except Exception:\n",
    "                print('While copying the parameter named {}, '\n",
    "                      'whose dimensions in the model are {} and '\n",
    "                      'whose dimensions in the checkpoint are {}.'\n",
    "                      .format(name, own_state[name].size(), param.size()))\n",
    "                print(\"But don't worry about it. Continue pretraining.\")\n",
    "\n",
    "def load_state(load_path, model, optimizer=None):\n",
    "    if os.path.isfile(load_path):\n",
    "        checkpoint = torch.load(load_path)\n",
    "        # model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "        # ckpt_keys = set(checkpoint['state_dict'].keys())\n",
    "        # own_keys = set(model.state_dict().keys())\n",
    "        # missing_keys = own_keys - ckpt_keys\n",
    "        # for k in missing_keys:\n",
    "        #     print('missing keys from checkpoint {}: {}'.format(load_path, k))\n",
    "        pretrain(model, checkpoint['state_dict'])\n",
    "\n",
    "        print(\"=> loaded model from checkpoint '{}'\".format(load_path))\n",
    "        if optimizer != None:\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> also loaded optimizer from checkpoint '{}' (epoch {})\"\n",
    "                  .format(load_path, start_epoch))\n",
    "            return\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(load_path))\n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    # for epoch in range(1, args.epochs + 1):\n",
    "    #     train(epoch)\n",
    "    #     test(epoch)\n",
    "    # torch.save({\n",
    "    #         'epoch': epoch ,\n",
    "    #         'state_dict': model.state_dict(),\n",
    "    #         'best_prec1': 0,\n",
    "    #         'optimizer': optimizer.state_dict(),\n",
    "    #     }, '%s_%s.pth.tar' % (args.save_path, epoch))\n",
    "    test_with_tsne(args.load_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
